AWSTemplateFormatVersion: "2010-09-09"
Description: Creates the infrastructure for capturing Transit Gateway Flow Logs on exceptional traffic levels. This version is deployed per Transit Gateway.

Parameters:
  TransitGatewayId:
    Type: String
    Description: The transit gateway ID to enabling alarming on attachments for.
    AllowedPattern: "^tgw-[0-9a-f]{17}$"
    ConstraintDescription: "Must be a valid Transit Gateway ID (e.g., tgw-0123456789abcdef0)"
  StdDev:
    Type: Number
    MinValue: 1
    MaxValue: 50
    Default: 2
    Description: By how many standard deviations should the anomaly detection threshold be set to?
  MinimumValue:
    Type: Number
    Default: 10000000
    Description: At very low usages, the standard deviation alarm will trigger on very low amounts. This parameter defines how many bytes per minute an attachment must have before we consider triggering on the detection threshold.
  MinutesBeforeStarting:
    Type: Number
    MinValue: 1
    Default: 2
    Description: How many minutes should the anomalies be occurring for before we alarm and start the capturing?
  ExistingSNSTopic:
    Type: String
    Description: If you have an existing SNS topic you want notifications sent to, provide the ARN here, otherwise leave blank and provide EmailAddress instead.
    AllowedPattern: "^$|^arn:[a-z0-9-]+:sns:[a-z0-9-]+:[0-9]{12}:[a-zA-Z0-9_-]+$"
    ConstraintDescription: "Must be a valid SNS topic ARN (e.g., arn:aws:sns:us-east-1:123456789012:MyTopic) or empty"
  EmailAddress:
    Type: String
    Description: Optionally, enter an email address here you want notifications sent to when captures start and stop. A new SNS topic will be created.
    AllowedPattern: "^$|[^@]+@[^@]+\\.[^@]+"
    ConstraintDescription: "Must be a valid email address (e.g., user@example.com) or empty"
  ExistingBucket:
    Type: String
    Description: Optionally, specify an existing S3 bucket to send logs into, otherwise leave blank. If you don't specify one, one will be created for you.
    AllowedPattern: "^$|^arn:[a-z0-9-]+:s3:::[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$"
    ConstraintDescription: "Must be a valid S3 bucket name (e.g., my-bucket-name) or S3 bucket ARN (e.g., arn:aws:s3:::my-bucket-name) or empty"
  MetricNamesToAlarm:
    Type: String
    Description: Comma-separated list of metrics to alarm on. The default just watches Bytes, but you may want to add in Packets.
    Default: BytesIn,BytesOut
  DaysToRetainFlowLogs:
    Type: Number
    Description: How many days should flow logs be left in the S3 buckets before being auto-deleted?
    MinValue: 1
    Default: 7

Rules:
  ValidateSNSConfiguration:
    Assertions:
      - Assert: !Not
          - !And
            - !Equals [!Ref ExistingSNSTopic, ""]
            - !Equals [!Ref EmailAddress, ""]
        AssertDescription: "You must provide either an ExistingSNSTopic ARN or an EmailAddress."
      - Assert: !Not
          - !And
            - !Not [!Equals [!Ref ExistingSNSTopic, ""]]
            - !Not [!Equals [!Ref EmailAddress, ""]]
        AssertDescription: "You must provide either an ExistingSNSTopic ARN or an EmailAddress, not both."


Conditions:
  MakeSNSTopic:
    Fn::Not:
      - Fn::Equals:
        - !Ref EmailAddress
        - ""
  MakeS3Bucket:
    Fn::Equals:
      - !Ref ExistingBucket
      - ""

Resources:
  S3Bucket:
    Type: AWS::S3::Bucket
    Condition: MakeS3Bucket
    Properties:
      LifecycleConfiguration:
        Rules:
          - Id: !Sub "RemoveAfter${DaysToRetainFlowLogs}Days"
            Status: Enabled
            ExpirationInDays: !Ref DaysToRetainFlowLogs
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      ObjectLockEnabled: true
      ObjectLockConfiguration:
        ObjectLockEnabled: Enabled
        Rule:
          DefaultRetention:
            Mode: GOVERNANCE
            Days: !Ref DaysToRetainFlowLogs
      VersioningConfiguration:
        Status: Enabled

  S3Policy:
    Type: AWS::S3::BucketPolicy
    Condition: MakeS3Bucket
    Properties:
      Bucket: !Ref S3Bucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
         - Sid: "AWSLogDeliveryWrite"
           Effect: "Allow"
           Principal:
             Service: "delivery.logs.amazonaws.com"
           Action: "s3:PutObject"
           Resource: !Sub "${S3Bucket.Arn}/transit_gateway_logs/*"
           Condition:
             StringEquals:
               "s3:x-amz-acl": "bucket-owner-full-control"
               "aws:SourceAccount": !Sub "${AWS::AccountId}"
             ArnLike:
               "aws:SourceArn": !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:*"
         - Sid: "AWSLogDeliveryCheck"
           Effect: "Allow"
           Principal:
             Service: "delivery.logs.amazonaws.com"
           Action:
             - "s3:GetBucketAcl"
             - "s3:ListBucket"
           Resource: !GetAtt S3Bucket.Arn
           Condition:
             StringEquals:
               "aws:SourceAccount": !Sub "${AWS::AccountId}"
             ArnLike:
               "aws:SourceArn": !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:*"
         - Sid: "DenyInsecureConnections"
           Effect: "Deny"
           Principal: "*"
           Action: "s3:*"
           Resource:
             - !GetAtt S3Bucket.Arn
             - !Sub "${S3Bucket.Arn}/*"
           Condition:
             Bool:
               "aws:SecureTransport": "false"
         - Sid: "DenyPublicReadWrite"
           Effect: "Deny"
           Principal: "*"
           Action:
             - "s3:GetObject"
             - "s3:PutObject"
             - "s3:DeleteObject"
           Resource: !Sub "${S3Bucket.Arn}/*"
           Condition:
             StringNotEquals:
               "aws:SourceAccount": !Sub "${AWS::AccountId}"

  SNSEncryptionKey:
    Type: AWS::KMS::Key
    Condition: MakeSNSTopic
    Properties:
      Description: "KMS key for SNS topic encryption"
      KeyPolicy:
        Version: '2012-10-17'
        Statement:
          - Sid: Allow administration of the key
            Effect: Allow
            Principal:
              AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Action: "kms:*"
            Resource: "*"
          - Sid: Allow SNS service
            Effect: Allow
            Principal:
              Service: sns.amazonaws.com
            Action:
              - "kms:Decrypt"
              - "kms:GenerateDataKey"
            Resource: "*"
          - Sid: Allow Lambda to use the key. We can't specify specific ARNs here due to dependency loops.
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action:
              - "kms:GenerateDataKey"
              - "kms:Decrypt"
            Resource: "*"
            Condition:
              StringEquals:
                "aws:SourceAccount": !Sub "${AWS::AccountId}"

  SNSTopic:
    Type: AWS::SNS::Topic
    Condition: MakeSNSTopic
    Properties:
      KmsMasterKeyId: !Ref SNSEncryptionKey
      Subscription:
        - Protocol: Email
          Endpoint: !Ref EmailAddress

  UpdateAttachmentsPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: !Sub Permissions needed for ${AWS::StackName}-UpdateAttachmentLambda to function
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: GlobalOperations
            Effect: Allow
            Resource: "*"
            Action:
              - "ec2:DescribeTransitGatewayAttachments"
          - Sid: AllowCloudwatchAlarmDiscovery
            Effect: Allow
            Resource: !Sub 'arn:${AWS::Partition}:cloudwatch:*:${AWS::AccountId}:alarm:*'
            Action:
              - "cloudwatch:DescribeAlarms"
          - Sid: AllowCloudwatchAlarmManipulation
            Effect: Allow
            Resource: !Sub 'arn:${AWS::Partition}:cloudwatch:${AWS::Region}:${AWS::AccountId}:alarm:*-Alarm-*'
            Action:
              - "cloudwatch:DescribeAlarms"
              - "cloudwatch:DeleteAlarms"
              - "cloudwatch:PutMetricAlarm"
              - "cloudwatch:SetAlarmState"
              - "cloudwatch:TagResource"
          - Sid: AllowSNSPublish
            Effect: Allow
            Action:
              - "sns:Publish"
            Resource: !If [MakeSNSTopic,!Ref SNSTopic,!Ref ExistingSNSTopic]
          - !If
            - MakeSNSTopic
            - Sid: AllowKMSKeyUse
              Effect: Allow
              Action:
                - "kms:GenerateDataKey"
                - "kms:Decrypt"
              Resource: !GetAtt SNSEncryptionKey.Arn
            - !Ref "AWS::NoValue"

  UpdateAttachmentsRole:
    Type: AWS::IAM::Role
    Properties:
      Description: !Sub Role for ${AWS::StackName}, region ${AWS::Region}, lambda UpdateAttachments
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: "/"
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
        - !Ref UpdateAttachmentsPolicy

  UpdateAttachmentsLambda:
    Type: AWS::Lambda::Function
    Properties:
      DeadLetterConfig:
        TargetArn: !If [ MakeSNSTopic, !Ref SNSTopic, !Ref ExistingSNSTopic ]
      Handler: index.handler
      Role: !GetAtt UpdateAttachmentsRole.Arn
      Runtime: python3.12
      Timeout: 120
      Environment:
        Variables:
          STACK_ARN: !Ref AWS::StackId
          TGW_ID: !Ref TransitGatewayId
          SNS_TOPIC: !If [MakeSNSTopic,!Ref SNSTopic,!Ref ExistingSNSTopic]
          METRIC_NAMES: !Ref MetricNamesToAlarm
          LAMBDA_REF: !GetAtt AlarmLambda.Arn
          STDDEV: !Ref StdDev
          MINIMUM_VALUE: !Ref MinimumValue
          MINUTES: !Ref MinutesBeforeStarting

      Code:
        ZipFile: |
          """
          Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
          SPDX-License-Identifier: MIT-0

          update_attachments.py
          Python lambda script to update our alarms with any new attachments. This script relies on environment variables to pass in how
          things should be configured. These are normally set by the CloudFormation template wrapping this script. Those variables are:

          STACK_ARN - The CloudFormation stack ARN used for this deployment
          TGW_ID - The Transit Gateway ID to monitor
          METRIC_NAMES - Comma-separated list of metrics to alarm on. ex: "BytesIn,BytesOut"
          STDDEV - By how many standard deviations should the anomaly detection threshold be set to, ex: "2"
          MINUTES - How many minutes should the anomalies be occurring for before we alarm and start the capturing?, ex: "2"
          MINIMUM_VALUE - At very low usages, the standard deviation alarm will trigger on very low amounts. This parameter defines how many bytes per minute an 
                          attachment must have before we consider triggering on the detection threshold.
          SNS_TOPIC - The SNS topic ARN to send notifications to
          LAMBDA_REF - The lambda ARN of the alarm handling function

          Additionally, it leverages some variables set by AWS Lambda itself - AWS_LAMBDA_FUNCTION_NAME and AWS_REGION.
          """
          import boto3
          import logging
          import os


          def set_alarm(tgwa_id: str, metric: str):
              logging.info(f'Setting alarm on attachment {tgwa_id} metric {metric}')
              cw = boto3.client('cloudwatch')
              tags_list=[{'Key': 'stack-arn', 'Value': os.environ['STACK_ARN']}, {'Key': 'attachment-id', 'Value': tgwa_id}, {'Key': 'metric', 'Value': metric}]

              # This format is made such that humans can understand the alarm easily in console view, although it makes
              # the scripting a bit harder by not having a consistent prefix.
              stack_id = os.environ['STACK_ARN'].split('/')[2]
              alarm_name = f'{metric}-{tgwa_id}-Alarm-{stack_id}'

              met = cw.put_metric_alarm(AlarmName=alarm_name,
                                        AlarmDescription=f'Anomaly detection alarm generated by lambda {os.environ['AWS_LAMBDA_FUNCTION_NAME']} from {os.environ['STACK_ARN']}',
                                        OKActions=[os.environ['LAMBDA_REF']], AlarmActions=[os.environ['LAMBDA_REF']],
                                        Metrics=[{'Id': 'm1',
                                                  'MetricStat': {'Metric': {'Namespace': 'AWS/TransitGateway', 'MetricName': metric, 'Dimensions': [{'Name': 'TransitGateway', 'Value': os.environ['TGW_ID']}, {'Name': 'TransitGatewayAttachment', 'Value': tgwa_id}]},
                                                                'Period': 60, 'Stat': 'Average'}, 'ReturnData': False},
                                                  {'Id': 'e1', 'Expression': f'ANOMALY_DETECTION_BAND(m1, {os.environ['STDDEV']})', 'Label': 'Anomaly Band', 'ReturnData': False},
                                                  {'Id': 'e2', 'Expression': f'IF(m1>{os.environ['MINIMUM_VALUE']} AND m1>MAX(e1),1,0)', 'Label': 'Alarm Trigger', 'ReturnData': True}],
                                        Threshold=0, ComparisonOperator='GreaterThanThreshold', EvaluationPeriods=int(os.environ['MINUTES']), DatapointsToAlarm=int(os.environ['MINUTES']), Tags=tags_list)
              print(f"Added an alarm to attachment ID {tgwa_id} metric {metric}.")    


          def clear_alarm(tgwa_id: str, metric: str):
              cw = boto3.client('cloudwatch')
              stack_id = os.environ['STACK_ARN'].split('/')[2]
              alarm_name = f'{metric}-{tgwa_id}-Alarm-{stack_id}'
              cw.set_alarm_state(AlarmName=alarm_name, StateValue='OK', StateReason="Alarm is being removed.")
              cw.delete_alarms(AlarmNames=[alarm_name])    
              print(f"Deleted alarm {alarm_name}.")


          def handler(event, context):
              try:
                  ec2 = boto3.client('ec2')
                  sns = boto3.client('sns')
                  cw = boto3.client('cloudwatch')

                  # Get current alarms by looking for our lambda as the action
                  current_alarms = {}
                  paginator = cw.get_paginator('describe_alarms')
                  resp = paginator.paginate(AlarmTypes=['MetricAlarm'], ActionPrefix=os.environ['LAMBDA_REF'])
                  for page in resp:
                      for alarm in page['MetricAlarms']:
                          if 'Metrics' in alarm:
                              # This is one of ours. Get the metric and attachment this alarm is monitoring, and mark it done already.
                              for metric in alarm['Metrics']:
                                  # Metrics will have the actual statistics we're monitoring (MetricStat) or may be a math function
                                  # which won't have that field, so make sure we check for that.
                                  if 'MetricStat' in metric:
                                      tgwa_id = None
                                      for dim in metric['MetricStat']['Metric']['Dimensions']:
                                          if dim['Name'] == 'TransitGatewayAttachment':
                                              tgwa_id = dim['Value']
                                      if tgwa_id not in current_alarms:
                                          current_alarms[tgwa_id] = {}
                                      # We set this to False for now, as we haven't verified this attachment still exists yet.
                                      # The loop below will set this to True for attachments we find. At the end, we go through 
                                      # this dict and any alarms that still exist but their attachments don't will get deleted.
                                      current_alarms[tgwa_id][metric['MetricStat']['Metric']['MetricName']] = False

                  # Find all current attachments, and make sure alarms are set
                  results = {'Added': 0, 'Deleted': 0}
                  paginator = ec2.get_paginator('describe_transit_gateway_attachments')
                  resp = paginator.paginate(Filters=[{'Name': 'transit-gateway-id', 'Values': [os.environ['TGW_ID']]}])
                  for page in resp:
                      for attachment in page['TransitGatewayAttachments']:
                          tgwa_id = attachment['TransitGatewayAttachmentId']
                          if tgwa_id not in current_alarms:
                              current_alarms[tgwa_id] = {}
                          for metric in os.environ['METRIC_NAMES'].split(','):
                              if (tgwa_id not in current_alarms) or (metric not in current_alarms[tgwa_id]):
                                  set_alarm(tgwa_id, metric)
                                  results['Added'] += 1
                                  current_alarms[tgwa_id][metric] = True
                              elif (tgwa_id in current_alarms and metric in current_alarms[tgwa_id]):
                                  current_alarms[tgwa_id][metric] = True
                  
                  # See if we have any alarms lingering around for attachments that we didn't find.  If so, delete them.
                  for tgwa_id, metrics in current_alarms.items():
                      for metric, found in metrics.items():
                          if not found:
                              clear_alarm(tgwa_id, metric)
                              results['Deleted'] += 1

              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  logging.error(f"Data from request:\nevent={event}\ncontext={context}")

                  # This next line could error again on us, but CFN has already been responded to, so this is a 'best-effort'
                  # type call.
                  sns = boto3.client('sns')
                  sns.publish(TopicArn=os.environ['SNS_TOPIC'], Subject=f'Lambda {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']} had an exception.',
                              Message=f'The lambda function {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']} had an exception.\n\n'
                              f'Exception: {e}\n\n'
                              f'Event data: {event}')
                  raise e


  UpdateAttachmentsRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub ${AWS::StackName}-CatchTGWAttachmentChanges
      ScheduleExpression: 'rate(30 minutes)'
      Targets:
        [{"Id": "1", "Arn": !GetAtt UpdateAttachmentsLambda.Arn}]

  AlarmIAMPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: !Sub Permissions needed for ${AWS::StackName}-AlarmLambda to function
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AllowSNSPublish
            Effect: Allow
            Action:
              - "sns:Publish"
            Resource: !If [MakeSNSTopic,!Ref SNSTopic,!Ref ExistingSNSTopic]
          - Sid: AllowFlowLogManipulation
            Effect: Allow
            Resource: "*"
            Action:
              - "ec2:DescribeFlowLogs"
              - "ec2:CreateFlowLogs"
              - "ec2:DeleteFlowLogs"
              - "ec2:CreateTags"
              - "logs:CreateLogDelivery"
          - !If
            - MakeSNSTopic
            - Sid: AllowKMSKeyUse
              Effect: Allow
              Action:
                - "kms:GenerateDataKey"
                - "kms:Decrypt"
              Resource: !GetAtt SNSEncryptionKey.Arn
            - !Ref "AWS::NoValue"

  AlarmRole:
    Type: AWS::IAM::Role
    Properties:
      Description: !Sub Role for ${AWS::StackName}, region ${AWS::Region}, lambda AlarmLambda
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: "/"
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
        - !Ref AlarmIAMPolicy

  AlarmPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref AlarmLambda
      Action: lambda:InvokeFunction
      Principal: "lambda.alarms.cloudwatch.amazonaws.com"
      SourceAccount: !Sub ${AWS::AccountId}

  AlarmLambda:
    Type: AWS::Lambda::Function
    Properties:
      DeadLetterConfig:
        TargetArn: !If [ MakeSNSTopic, !Ref SNSTopic, !Ref ExistingSNSTopic ]
      Handler: index.handler
      Role: !GetAtt AlarmRole.Arn
      Runtime: python3.12
      Timeout: 30
      Environment:
        Variables:
          S3_BUCKET: !If [MakeS3Bucket,!Ref S3Bucket,!Ref ExistingBucket]
          SNS_TOPIC: !If [MakeSNSTopic,!Ref SNSTopic,!Ref ExistingSNSTopic]
      Code:
        ZipFile: |
          """
          Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
          SPDX-License-Identifier: MIT-0
          
          alarm_handler.py
          
          Python lambda script to handle CloudWatch alarms being set and cleared, triggering captures on the affected
          Transit Gateway attachment.
          
          This script relies on environment variables to pass in how things work. Those variables are:
          
          S3_BUCKET - The full ARN of the bucket and path to save flow logs into
          SNS_TOPIC - The SNS topic ARN to send notifications to
          
          Additionally, it leverages some variables set by AWS Lambda itself - AWS_LAMBDA_FUNCTION_NAME and AWS_REGION.
          
          API references:
          https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2/client/create_flow_logs.html
          https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2/client/describe_flow_logs.html
          """
          import boto3
          import logging
          import os
          import datetime
          
          # Change this to be whatever fields you like. The default, provided here, are all fields.
          # See https://docs.aws.amazon.com/vpc/latest/tgw/tgw-flow-logs.html#flow-log-records for information.
          TGW_FLOW_LOG_FORMAT = '${version} ${resource-type} ${account-id} ${tgw-id} ${tgw-attachment-id} ${tgw-src-vpc-account-id} ${tgw-dst-vpc-account-id} ${tgw-src-vpc-id} ${tgw-dst-vpc-id} ${tgw-src-subnet-id} ${tgw-dst-subnet-id} ${tgw-src-eni} ${tgw-dst-eni} ${tgw-src-az-id} ${tgw-dst-az-id} ${tgw-pair-attachment-id} ${srcaddr} ${dstaddr} ${srcport} ${dstport} ${protocol} ${packets} ${bytes} ${start} ${end} ${log-status} ${type} ${packets-lost-no-route} ${packets-lost-blackhole} ${packets-lost-mtu-exceeded} ${packets-lost-ttl-expired} ${tcp-flags} ${region} ${flow-direction} ${pkt-src-aws-service} ${pkt-dst-aws-service}'
          CREATOR_TAG = f"Lambda {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']}"
          
          def get_flow_log_status(ec2: object, resource_id: str) -> bool:
              """
              Determine current flow log status
          
              :param ec2: Boto3 EC2 Client
              :param resource_id: As per create_flow_log ResourceId
          
              :return: Return True if a flow log is already active for this object, False otherwise.
              """
              fls = ec2.describe_flow_logs(Filters=[{'Name': 'resource-id', 'Values': [resource_id]}])
              for fl in fls['FlowLogs']:
                  if fl['ResourceId'] == resource_id:
                      if fl['FlowLogStatus'] == 'ACTIVE' and 'Tags' in fl:
                              for tag in fl['Tags']:
                                  if tag['Key'] == 'Creator' and tag['Value'] == CREATOR_TAG:
                                      return True
              return False
          
          
          def format_bytes(bytes_value: float) -> str:
              """
              Format bytes into human readable format.
              :param bytes_value: Number of bytes
              :return: Formatted string
              """
              for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
                  if bytes_value < 1024.0:
                      return f"{bytes_value:.1f} {unit}"
                  bytes_value /= 1024.0
              return f"{bytes_value:.1f} PB"
          
          
          def convert_to_metric(d: dict) -> dict:
              # The AlarmData has the metric info, but:
              # - Every key is lowercase instead of upper like we need to GetMetricStats
              # - It's Name instead of MetricName
              # - The Dimensions are in a different format.
              # Correct this.
              ret = {}
              for k, v in d.items():
                  newk = k[0].upper() + k[1:]
                  if newk == 'Name':
                      newk = 'MetricName'
                  if isinstance(v, dict):
                      if newk == 'Dimensions':
                          ret[newk] = [{'Name': k, 'Value': v} for k, v in convert_to_metric(v).items()]
                      else:
                          ret[newk] = convert_to_metric(v)
                  else:
                      if newk == 'ReturnData':
                          ret[newk] = True
                      else:
                          ret[newk] = v
          
              return ret
          
          
          def get_alarming_metric_str(alarm_data: dict) -> str:
              # We have a composite alarm - while the alarm we create is named something like BytesOut-tgw-tgw-attach-0ab9d8b7bcab228d4-alarms-Alarm,
              # that by itself doesn't help - it's two 1 or 0 evaluations. We have to get the alarm configuration and get the 'm1' metric to get the
              # actual values. Start with getting the metric.
              cw = boto3.client('cloudwatch')
              alarming_metric = None
          
              # Get metric dimensions
              for m in alarm_data['configuration']['metrics']:
                  if 'metricStat' in m:
                      alarming_metric = convert_to_metric(m)
                      break
              if alarming_metric is None:
                  print(f'Unable to find the metric for alarm_data {alarm_data}')
                  return ''
          
              # Get most recent data point and detection band for that metric
              endtime = datetime.datetime.now(datetime.timezone.utc)
              starttime = endtime - datetime.timedelta(minutes=15)
              mdq = [alarming_metric, {"Id": "ab1", "Expression": "ANOMALY_DETECTION_BAND(m1)"}]
              metric_data = cw.get_metric_data(MetricDataQueries=mdq, EndTime=endtime, StartTime=starttime, MaxDatapoints=1, ScanBy='TimestampDescending')
              if len(metric_data['MetricDataResults']) == 0 or len(metric_data['MetricDataResults'][0]['Values']) == 0:
                  print(f'Unable to get metric data for alarm_data {alarm_data}')
                  return ''
          
              # Get current value and the high water AD band. Convert units for a couple common metrics.
              cur_value = None
              high_band = None
              for md in metric_data['MetricDataResults']:
                  if md['Id'] == 'm1':
                      cur_value = md['Values'][0]
                  elif md['Id'] == 'ab1' and md['Label'][-4:] == 'High':
                      high_band = md['Values'][0]
          
              if alarming_metric['MetricStat']['Metric']['MetricName'] in ('BytesIn', 'BytesOut'):
                  cur_value = format_bytes(cur_value)
                  high_band = format_bytes(high_band)
          
              # We have everything now - return string
              return f"Alarm Information:\nAlarm: {alarm_data['alarmName']}\nCurrent value: {cur_value} per minute\nAnomaly detection high band: {high_band} per minute.\n\n"
          
          
          def disable_flow_log(ec2: object, sns: object, resource_type: str, resource_id: str, s3_dest_arn: str, logging_sns: str, alarm_data: dict):
              """
              Disable a flow log for the given resource.
              :param ec2: Boto3 EC2 Client
              :param sns: Boto3 SNS Client
              :param resource_type: As per create_flow_log ResourceType
              :param resource_id: As per create_flow_log ResourceId
              :param s3_dest_arn: S3 destination ARN, ala arn:aws:s3:::bucket/subfolder/
              :param logging_sns: SNS topic to send state changes to.
              """
              fls = ec2.describe_flow_logs(Filters=[{'Name': 'resource-id', 'Values': [resource_id]}])
              start_time = None
              for fl in fls['FlowLogs']:
                  if fl['ResourceId'] == resource_id and fl['FlowLogStatus'] == 'ACTIVE' and 'Tags' in fl:
                      for tag in fl['Tags']:
                          if tag['Key'] == 'Creator' and tag['Value'] == CREATOR_TAG:
                              ret = ec2.delete_flow_logs(FlowLogIds=[fl['FlowLogId']])
                              if len(ret['Unsuccessful']):
                                  raise Exception(f"Unable to delete flow log for {resource_type}, {resource_id}, at {s3_dest_arn}: {ret['Unsuccessful'][0]['Error']}")
                              start_time = fl['CreationTime']
              if start_time is None:
                  print(f"disable_flow_log called for a flow log that doesn't exist ({resource_type}, {resource_id}, {s3_dest_arn}). Ignoring.")
                  return
          
              print(f'Stopped flow log for {resource_type}, {resource_id}, at {s3_dest_arn}')
          
              # Build the S3 path to help the person receiving the email out. The path is based on date in UTC - get that.
              utc = datetime.datetime.now(datetime.timezone.utc)
              account_id = boto3.client('sts').get_caller_identity().get('Account')
              s3_path = f's3://{s3_dest_arn.split(':')[-1]}/AWSLogs/{account_id}/vpcflowlogs/{os.environ['AWS_REGION']}/{utc.year}/{utc.month:02}/{utc.day:02}'
          
              # How long did we have the flow log for?
              end_time = datetime.datetime.now(start_time.tzinfo)
              delta_time = end_time - start_time
          
              sns.publish(TopicArn=logging_sns, Subject=f'Disabled flow log for {resource_type}, {resource_id}',
                          Message=f'Flow logging has been disabled on {resource_type} ID {resource_id} to {s3_dest_arn}. It ran for {delta_time}.\n\n'
                                  f'You can view the logs collected by running aws s3 ls {s3_path}/\n\n'
                                  f'{get_alarming_metric_str(alarm_data)}'
                                  f'This message is from lambda function {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in region {os.environ['AWS_REGION']}.')
          
          
          def enable_flow_log(ec2: object, sns: object, resource_type: str, resource_id: str, s3_dest_arn: str, logging_sns: str, alarm_data: dict):
              """
              Enable a flow log for the given resource.
              :param ec2: Boto3 EC2 Client
              :param sns: Boto3 SNS Client
              :param resource_type: As per create_flow_log ResourceType
              :param resource_id: As per create_flow_log ResourceId
              :param s3_dest_arn: S3 destination ARN, ala arn:aws:s3:::bucket/subfolder/
              :param logging_sns: SNS topic to send state changes to.
              """
              client_token = f'{resource_type}-{resource_id}-enable'
              ret = ec2.create_flow_logs(ClientToken=client_token, ResourceType=resource_type, ResourceIds=[resource_id],
                                         LogDestinationType='s3', LogDestination=s3_dest_arn, LogFormat=TGW_FLOW_LOG_FORMAT,
                                         TagSpecifications=[{'ResourceType': 'vpc-flow-log', 'Tags': [{'Key': 'Creator', 'Value': f'Lambda {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']}'}]}])
          
              if len(ret['Unsuccessful']):
                  raise Exception(f"Unable to create flow log for {resource_type}, {resource_id}, at {s3_dest_arn}: {ret['Unsuccessful'][0]['Error']}")
          
              print(f'Started flow log for {resource_type}, {resource_id}, at {s3_dest_arn}')
          
              # Build the S3 path to help the person receiving the email out. The path is based on date in UTC - get that.
              utc = datetime.datetime.now(datetime.timezone.utc)
              account_id = boto3.client('sts').get_caller_identity().get('Account')
              s3_path = f's3://{s3_dest_arn.split(':')[-1]}/AWSLogs/{account_id}/vpcflowlogs/{os.environ['AWS_REGION']}/{utc.year}/{utc.month:02}/{utc.day:02}'
          
              sns.publish(TopicArn=logging_sns, Subject=f'Enabled flow log for {resource_type}, {resource_id}',
                          Message=f'Flow logging has been enabled on {resource_type} ID {resource_id} to {s3_dest_arn}.\n\n'
                                  f'You can view the logs collected by running: aws s3 ls {s3_path}/\n\n'
                                  f'{get_alarming_metric_str(alarm_data)}'
                                  f'This message is from lambda function {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in region {os.environ['AWS_REGION']}.')
          
          def set_flow_log(ec2: object, sns: object, resource_type: str, resource_id: str, s3_dest_arn: str, enabled: bool, logging_sns: str, alarm_data: dict):
              """
              Ensures a flow log is set for the given resource. Adds or deletes as needed, but won't do anything if the
              state is already correct.
          
              :param ec2: Boto3 EC2 Client
              :param sns: Boto3 SNS Client
              :param resource_type: As per create_flow_log ResourceType
              :param resource_id: As per create_flow_log ResourceId
              :param s3_dest_arn: S3 destination ARN, ala arn:aws:s3:::bucket/subfolder/
              :param enabled: True to ensure the log is enabled, False to ensure it is disabled.
              :param logging_sns: SNS topic to send state changes to.
              :return:
              """
          
              # See if we have a log going currently.
              current_status = get_flow_log_status(ec2, resource_id)
          
              # Do we need to do a state change? If so, do it.
              if current_status and not enabled:
                  disable_flow_log(ec2, sns, resource_type, resource_id, s3_dest_arn, logging_sns, alarm_data)
              elif not current_status and enabled:
                  enable_flow_log(ec2, sns, resource_type, resource_id, s3_dest_arn, logging_sns, alarm_data)
              else:
                  print(f'No flow log state change needed for {resource_type}, {resource_id}, at {s3_dest_arn} - current status is {current_status}, enabled is {enabled}')
          
          
          def handler(event, context):
              try:
                  ec2 = boto3.client('ec2')
                  sns = boto3.client('sns')
          
                  # See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html for an example o
                  # the event object that is being sent here.
                  print(f"Processing alarm event. Event data {event}")
          
                  # Make sure this is a Transit Gateway attachment.
                  if event['alarmData']['configuration']['metrics'][0]['metricStat']['metric']['namespace'] == 'AWS/TransitGateway':
                      tgw_attachment_id = event['alarmData']['configuration']['metrics'][0]['metricStat']['metric']['dimensions']['TransitGatewayAttachment']
                      # This will be True if we're going into alarm, or False when we're coming out of it.
                      set_or_reset = event['alarmData']['state']['value'] == 'ALARM'
                      # Where will this go?
                      s3_dest_arn = f'arn:aws:s3:::{os.environ['S3_BUCKET']}/transit_gateway_logs/{tgw_attachment_id}'
                      set_flow_log(ec2, sns, 'TransitGatewayAttachment', tgw_attachment_id, s3_dest_arn, set_or_reset, os.environ['SNS_TOPIC'], event['alarmData'])
                  return
          
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  logging.error(f"Data from request:\nevent={event}\ncontext={context}")
          
                  # This next line could error again on us, but CFN has already been responded to, so this is a 'best-effort'
                  # type call.
                  sns.publish(TopicArn=os.environ['SNS_TOPIC'], Subject=f'Lambda {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']} had an exception.',
                              Message=f'The lambda function {os.environ['AWS_LAMBDA_FUNCTION_NAME']} in {os.environ['AWS_REGION']} had an exception.\n\n'
                              f'Exception: {e}\n\n'
                              f'Event data: {event}')
                  raise e
